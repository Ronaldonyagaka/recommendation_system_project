{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style= \"color:cyan\"> AMAZON BOOK RECOMMENDATION SYSTEM </SPAN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the era of exponential data growth, the emergence of more sophisticated systems leveraging big data has become increasingly prevalent. Among these systems, recommendation systems have proven to be valuable information filtering tools, enhancing search results by providing users with more relevant items based on their search queries or browsing history. Major technology companies have embraced recommendation systems across various applications: YouTube utilizes them to determine the next autoplay video, while Spotify employs them to curate personalized \"Made for You\" daily mixes.\n",
    "\n",
    "In line with this project's objectives, we aim to harness the power of data analysis to recommend the best books to users. By examining user behaviors, both individual and collective, we can derive insights that enable us to deliver tailored book recommendations that align with their interests and preferences.\n",
    "\n",
    "The underlying principle of this project is to leverage data-driven techniques to understand user preferences and behaviors. By analyzing user interactions, historical data, and patterns, we can uncover valuable insights that inform our recommendation system. This allows us to present users with a curated list of book suggestions that are highly likely to resonate with their tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon is looking to optimize their recommendation system such that it will suggest different and new books while increasing their profitability margin, the company has seen a slight decrease in sales as a result of suggesting old and most frequent books on the platform.\n",
    "\n",
    "While Amazon remains a dominant player in the marker, other platforms such as Barnes & Noble, Alibris, Smashwords etc. have gained popularity and they can be considered as potential competitors which is threatening to the platform\n",
    "We have therefore been appointed as Junior Data Scientists by Amazon so as to optimize their book recommendation system. This will enhance customer engagement, improve sales and revenue, increase book discovery and personalize user experience for their competitive advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Book-Crossing dataset comprises 3 files:\n",
    "\n",
    "- **Users**: Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL values.\n",
    "- **Books**: Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in the case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavors (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon website.\n",
    "- **Ratings**: Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Business Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To develop a book recommendation system that provides personalized suggestions to users based on their individual preferences and reading history.\n",
    "2. To analyze top popular books and recommend them to increase revenue\n",
    "3. To utilize the recommendation systems insights to identify peak hours of the day when users are mostly active, allowing for better optimization of online ad campaigns to target book enthusiast during most engaged periods.\n",
    "4. To investigate the relationship between book unit prices and quantity demanded to determine if there are any significant correlations.\n",
    "5. To monitor market trends, new book releases and emerging genres to update and refine the recommendation system, ensuring it remains relevant and up to date in the ever changing book landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Determining The Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Develop a prediction model within the book recommendation system that can accurately forecast the likelihood of a specific user showing interest in a particular book, based on their historical data, preferences, and interactions.\n",
    "- Implement a mechanism to handle new users joining the book recommendation system, providing them with initial recommendations that align with their interests and preferences. This will involve utilizing demographic information, user profiling, and collaborative filtering techniques to generate relevant book suggestions.\n",
    "- Establish evaluation metrics to assess the performance of the recommendation system, such as precision, recall, and mean average precision.\n",
    "- Create a function that will return top N recommendations for a user.\n",
    "- Deploy and Implement a real-time recommendation feature that can adapt to users' changing preferences and provide up-to-date book suggestions. This involves continuously updating the recommendation model, incorporating new user interactions, and leveraging real-time data to deliver timely and relevant recommendations.\n",
    "- Optimize a recommender system that can recommend books to new users thus solving the cold start problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6  Determining the project success criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.    RMSE of less than 0.8\n",
    "2.    Accuracy of 70% +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Methods Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive Statistics\n",
    "- Data Visualization\n",
    "- Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 DATA UNDERSTANDING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the necessary libraries and modules for the project:\n",
    "\n",
    "The code below imports the necessary libraries and modules for the project. Here's a breakdown of the imported libraries and their purposes:\n",
    "\n",
    "- **pandas** and **numpy**: Data manipulation and analysis.\n",
    "- **seaborn** and **matplotlib**: Data visualization and plotting.\n",
    "- **surprise**: Library for collaborative filtering-based recommendation systems.\n",
    "- **scikit-learn**: Preprocessing and evaluation of the recommendation system.\n",
    "- **warnings**: Ignoring warning messages.\n",
    "- **scipy**, **math**, and **nltk**: Libraries for text-based recommendation systems.\n",
    "- **LightFM**: Library for hybrid recommendation systems.\n",
    "\n",
    "These libraries provide the functionality needed to perform data analysis, preprocessing, modeling, and evaluation for the book recommendation system. The code ensures that any warning messages are ignored to maintain clean output.\n",
    "\n",
    "The imported libraries will be used in subsequent code cells to implement different aspects of the book recommendation system, such as collaborative filtering, content-based filtering, and hybrid recommendation approaches.\n",
    "\n",
    "By importing these libraries, we can leverage their functionalities and methods to build a robust and accurate book recommendation system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Surprise library for collaborative filtering\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD, SVDpp\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Scikit-learn for preprocessing and evaluation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Scipy, math, and nltk libraries for text-based recommendation\n",
    "import scipy\n",
    "import math\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# LightFM library for hybrid recommendation\n",
    "from scipy.sparse import csr_matrix\n",
    "from lightfm import LightFM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from Files:\n",
    "\n",
    "The code defines a function called `read_data` that reads data from a given file path using the `pd.read_csv()` function from the pandas library. It has the following parameters:\n",
    "\n",
    "- `path`: The file path of the data to be read.\n",
    "- `error_bad_lines`: A flag to handle lines with errors. By default, it is set to `False`.\n",
    "- `encoding`: The encoding format of the file. The default is set to `'latin-1'`.\n",
    "- `sep`: The delimiter used in the file. The default is set to `';'`.\n",
    "- `on_bad_lines`: Action to be taken when encountering bad lines. By default, it is set to `'skip'`.\n",
    "\n",
    "The function reads the data from the specified file path using the given parameters and returns the data as a pandas DataFrame.\n",
    "\n",
    "The code then calls the `read_data` function three times to read three different files: `BX-Book-Ratings.csv`, `BX-Books.csv`, and `BX-Users.csv`. The file paths are provided as arguments to the function.\n",
    "\n",
    "The resulting DataFrames are assigned to the variables `book_ratings`, `books`, and `users`, respectively.\n",
    "\n",
    "These DataFrames will be used for further analysis, preprocessing, and modeling in the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, error_bad_lines = False, encoding = 'latin-1', sep=';', on_bad_lines = 'skip'):\n",
    "\n",
    "    \"A simple function that reads the data\"\n",
    "    \n",
    "    data = pd.read_csv(path, error_bad_lines = error_bad_lines, encoding = encoding, sep = sep)\n",
    "    return data\n",
    "\n",
    "book_ratings = read_data(r'C:\\Users\\user\\Documents\\Recommendation Systems\\recommendation_system_project\\BX-Book-Ratings.csv')\n",
    "books = read_data(r'C:\\Users\\user\\Documents\\Recommendation Systems\\recommendation_system_project\\BX-Books.csv')\n",
    "users = read_data(r'C:\\Users\\user\\Documents\\Recommendation Systems\\recommendation_system_project\\BX-Users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the First 5 Rows of the DataFrames\n",
    "we have three datasets:\n",
    "* `books`\n",
    "* `users`\n",
    "* `rating`\n",
    "\n",
    "Let us explore them by viewing first five rows of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-61052b6f19a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" calling on variable book_ratings to view the first 5 rows\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbook_ratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'book_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" calling on variable book_ratings to view the first 5 rows\"\"\"\n",
    "\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" calling on variable books to view the first five rows\"\"\"\n",
    "\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" calling on variable users to view the first 5 rows\"\"\"\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style= \"color:orange\"> Preliminary Data understanding </SPAN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple function to check the shape, info and descriptive statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_info_shape_stats(dataset, dataset_name):\n",
    "\n",
    "    \"\"\"A simple function to check the shape, info and descriptive statistics of the dataset\"\"\"\n",
    "    \n",
    "    print('The Dataset:', dataset_name )\n",
    "    print(f\"has {dataset.shape[0]} rows and {dataset.shape[1]} columns\")\n",
    "    print('---------------------------')\n",
    "    print('---------------------------')\n",
    "    print(dataset.info())\n",
    "    print('---------------------------')\n",
    "    print('----------------------------')\n",
    "    print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling on the function get_info_shape_stats on the Book Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Book Ratings\n",
      "has 1149780 rows and 3 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "            User-ID   Book-Rating\n",
      "count  1.149780e+06  1.149780e+06\n",
      "mean   1.403864e+05  2.866950e+00\n",
      "std    8.056228e+04  3.854184e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n"
     ]
    }
   ],
   "source": [
    "\"\"\"calling on the function get_info_shape_stats\"\"\"\n",
    "\n",
    "get_info_shape_stats(book_ratings, 'Book Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'book_ratings' dataset contains a total of 1,149,780 rows and 3 columns. Here are some key observations about the dataset:\n",
    "\n",
    "- The dataset consists of the following columns:\n",
    "    - User-ID: An anonymized identifier for the users.\n",
    "    - ISBN: The unique identifier for the books.\n",
    "    - Book-Rating: The rating given by the users for the books. Ratings range from 0 to 10, with higher values indicating higher appreciation.\n",
    "\n",
    "- The dataset has no missing values as indicated by the 'Non-Null Count' column.\n",
    "\n",
    "- Data types:\n",
    "    - User-ID and Book-Rating columns are of integer type (int64).\n",
    "    - ISBN column is of object type (string).\n",
    "\n",
    "- Descriptive Statistics:\n",
    "    - The mean book rating is approximately 2.87, indicating a relatively low average rating.\n",
    "    - The standard deviation of book ratings is around 3.85, indicating a wide range of rating values.\n",
    "    - The minimum book rating is 0, while the maximum rating is 10.\n",
    "    - The majority of book ratings (75%) fall within the range of 0 to 7.\n",
    "\n",
    "These observations provide an initial understanding of the 'book_ratings' dataset and its characteristics. Further analysis and processing can be performed based on this information to build the recommendation system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling on the function get_info_shape_stats on the Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Books\n",
      "has 271360 rows and 8 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271360 entries, 0 to 271359\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 271360 non-null  object\n",
      " 1   Book-Title           271360 non-null  object\n",
      " 2   Book-Author          271359 non-null  object\n",
      " 3   Year-Of-Publication  271360 non-null  object\n",
      " 4   Publisher            271358 non-null  object\n",
      " 5   Image-URL-S          271360 non-null  object\n",
      " 6   Image-URL-M          271360 non-null  object\n",
      " 7   Image-URL-L          271357 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 16.6+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "              ISBN      Book-Title      Book-Author  Year-Of-Publication  \\\n",
      "count       271360          271360           271359               271360   \n",
      "unique      271360          242135           102023                  202   \n",
      "top     0316140716  Selected Poems  Agatha Christie                 2002   \n",
      "freq             1              27              632                13903   \n",
      "\n",
      "        Publisher                                        Image-URL-S  \\\n",
      "count      271358                                             271360   \n",
      "unique      16807                                             271044   \n",
      "top     Harlequin  http://images.amazon.com/images/P/188364254X.0...   \n",
      "freq         7535                                                  2   \n",
      "\n",
      "                                              Image-URL-M  \\\n",
      "count                                              271360   \n",
      "unique                                             271044   \n",
      "top     http://images.amazon.com/images/P/075284332X.0...   \n",
      "freq                                                    2   \n",
      "\n",
      "                                              Image-URL-L  \n",
      "count                                              271357  \n",
      "unique                                             271041  \n",
      "top     http://images.amazon.com/images/P/349922271X.0...  \n",
      "freq                                                    2  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"calling on the function get_info_shape_stats\"\"\"\n",
    "\n",
    "get_info_shape_stats(books, 'Books')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'books' dataset contains a total of 271,360 rows and 8 columns. Here are some key observations about the dataset:\n",
    "\n",
    "- The dataset consists of the following columns:\n",
    "    - ISBN: The unique identifier for the books.\n",
    "    - Book-Title: The title of the books.\n",
    "    - Book-Author: The author of the books.\n",
    "    - Year-Of-Publication: The year when the books were published.\n",
    "    - Publisher: The publisher of the books.\n",
    "    - Image-URL-S: The URL of the small-sized cover image of the books.\n",
    "    - Image-URL-M: The URL of the medium-sized cover image of the books.\n",
    "    - Image-URL-L: The URL of the large-sized cover image of the books.\n",
    "\n",
    "- The dataset has some missing values in the 'Book-Author', 'Publisher', and 'Image-URL-L' columns, as indicated by the 'Non-Null Count' column.\n",
    "\n",
    "- Data types:\n",
    "    - All columns in the dataset are of object type (string).\n",
    "\n",
    "- Descriptive Statistics:\n",
    "    - The dataset has 271,360 unique ISBN values, indicating no duplicate ISBNs.\n",
    "    - The most frequent book in the dataset is \"Selected Poems\" with 27 occurrences.\n",
    "    - The most frequent book author is \"Agatha Christie\" with 632 occurrences.\n",
    "    - The most common year of publication is 2002, with 13,903 books published in that year.\n",
    "    - The dataset includes books from various publishers, with the most frequent publisher being \"Harlequin\" with 7,535 occurrences.\n",
    "\n",
    "These observations provide an initial understanding of the 'books' dataset and its characteristics. Further analysis and processing can be performed based on this information to enhance the book recommendation system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calling on the function get_info_shape_stats on the Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Users\n",
      "has 278858 rows and 3 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278858 entries, 0 to 278857\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   User-ID   278858 non-null  int64  \n",
      " 1   Location  278858 non-null  object \n",
      " 2   Age       168096 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "            User-ID            Age\n",
      "count  278858.00000  168096.000000\n",
      "mean   139429.50000      34.751434\n",
      "std     80499.51502      14.428097\n",
      "min         1.00000       0.000000\n",
      "25%     69715.25000      24.000000\n",
      "50%    139429.50000      32.000000\n",
      "75%    209143.75000      44.000000\n",
      "max    278858.00000     244.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"calling on the function get_info_shape_stats\"\"\"\n",
    "\n",
    "get_info_shape_stats(users, 'Users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'users' dataset contains a total of 278,858 rows and 3 columns. Here are some key observations about the dataset:\n",
    "\n",
    "- The dataset consists of the following columns:\n",
    "    - User-ID: An anonymized unique identifier for the users.\n",
    "    - Location: The location of the users.\n",
    "    - Age: The age of the users.\n",
    "\n",
    "- The dataset has some missing values in the 'Age' column, as indicated by the difference between the 'Non-Null Count' and the total number of rows.\n",
    "\n",
    "- Data types:\n",
    "    - The 'User-ID' column is of integer type.\n",
    "    - The 'Location' column is of object type (string).\n",
    "    - The 'Age' column is of float type.\n",
    "\n",
    "- Descriptive Statistics:\n",
    "    - The dataset has 278,858 unique User-ID values, indicating no duplicate User-IDs.\n",
    "    - The minimum age in the dataset is 0, indicating some missing or invalid age values.\n",
    "    - The maximum age in the dataset is 244, which could be an outlier or erroneous value.\n",
    "    - The average age of the users is approximately 34.75, with a standard deviation of 14.43.\n",
    "    - The age values range from 0 to 244, with the majority of users falling within the 24 to 44 age range.\n",
    "\n",
    "These observations provide an initial understanding of the 'users' dataset and its characteristics. Further analysis and processing can be performed based on this information to enhance the book recommendation system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a function to check the data types on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_types(data, dataset_name):\n",
    "\n",
    "    \"\"\"A simple function to check the data types on th datasets \"\"\"\n",
    "\n",
    "    print(\"Dataset:\",dataset_name, \"has\",len( data.select_dtypes(include='number').columns),\n",
    "                \"Numeric columns\")\n",
    "    \n",
    "    print(\"and\", len(data.select_dtypes(include='object').columns),\n",
    "          \"Categorical columns\")\n",
    "\n",
    "    print('*****************************************************')\n",
    "    print('*****************************************************')\n",
    "\n",
    "    print('Numerical Columns:', data.select_dtypes(include='number').columns)\n",
    "    print('Categorical Coulumns:', data.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the data_types function to get an overview of the data types in the 'users' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Users has 2 Numeric columns\n",
      "and 1 Categorical columns\n",
      "*****************************************************\n",
      "*****************************************************\n",
      "Numerical Columns: Index(['User-ID', 'Age'], dtype='object')\n",
      "Categorical Coulumns: Index(['Location'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" calling on the data_types function \"\"\"\n",
    "\n",
    "data_types(users, 'Users') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'users' dataset has 2 numerical columns and 1 categorical column. Here's a breakdown of the columns:\n",
    "\n",
    "- Numerical Columns: 'User-ID' and 'Age'\n",
    "    - The 'User-ID' column is of type 'object'.\n",
    "    - The 'Age' column is of type 'object'.\n",
    "\n",
    "- Categorical Column: 'Location'\n",
    "    - The 'Location' column is of type 'object'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the data_types function to get an overview of the data types in the 'books' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Books has 0 Numeric columns\n",
      "and 8 Categorical columns\n",
      "*****************************************************\n",
      "*****************************************************\n",
      "Numerical Columns: Index([], dtype='object')\n",
      "Categorical Coulumns: Index(['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher',\n",
      "       'Image-URL-S', 'Image-URL-M', 'Image-URL-L'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" calling on the data_types function \"\"\"\n",
    "\n",
    "data_types(books, 'Books')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'users' dataset has 2 numerical columns and 1 categorical column. Here's a breakdown of the columns:\n",
    "\n",
    "- Numerical Columns: 'User-ID' and 'Age'\n",
    "    - The 'User-ID' column is of type 'object'.\n",
    "    - The 'Age' column is of type 'object'.\n",
    "\n",
    "- Categorical Column: 'Location'\n",
    "    - The 'Location' column is of type 'object'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the data_types function to get an overview of the data types in the 'book_ratings' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Book Ratings has 2 Numeric columns\n",
      "and 1 Categorical columns\n",
      "*****************************************************\n",
      "*****************************************************\n",
      "Numerical Columns: Index(['User-ID', 'Book-Rating'], dtype='object')\n",
      "Categorical Coulumns: Index(['ISBN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" calling on the data_types function \"\"\"\n",
    "\n",
    "data_types(book_ratings, 'Book Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'book_ratings' dataset has 2 numerical columns and 1 categorical column. Here's a breakdown of the columns:\n",
    "\n",
    "- Numerical Columns: 'User-ID', 'Book-Rating'\n",
    "    - The 'User-ID' and 'Book-Rating' columns are of type 'int64'.\n",
    "\n",
    "- Categorical Column: 'ISBN'\n",
    "    - The 'ISBN' column is of type 'object'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a function that iterates through the rows of the dataset to check for duplicates\n",
    "\n",
    "By checking for duplicates in the dataset, we can identify and handle any redundant or repeated data, ensuring the integrity and accuracy of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = []\n",
    "\n",
    "def check_duplicates(data):\n",
    "\n",
    "    \"\"\"Function that iterates through the rows of our dataset to check whether they are duplicated or not\"\"\"\n",
    "    \n",
    "    for i in data.duplicated():\n",
    "        duplicates.append(i)\n",
    "    duplicates_set = set(duplicates)\n",
    "    if(len(duplicates_set) == 1):\n",
    "        print('The Dataset has No Duplicates')\n",
    "\n",
    "    else:\n",
    "        duplicates_percentage = np.round(((sum(duplicates)/len(data)) * 100 ), 2)\n",
    "        print(f'Duplicated rows constitute of {duplicates_percentage} % of our dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicates in book_ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_duplicates(book_ratings) # checking for duplicates in book_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the function indicates that the dataset has no duplicates. This means that each row in the book_ratings dataset is unique and there are no repeated entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicates in books Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has No Duplicates\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(books) # checking for duplicates in books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the function indicates that the dataset has no duplicates. This means that each row in the books dataset is unique and there are no repeated entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicates in users Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_duplicates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f8779c4d2ac9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheck_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# checking for duplicates in users\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'check_duplicates' is not defined"
     ]
    }
   ],
   "source": [
    "check_duplicates(users) # checking for duplicates in users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the function indicates that the dataset has no duplicates. This means that each row in the users dataset is unique and there are no repeated entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Missing Values\n",
    "\n",
    "By identifying and addressing missing values, we can verify the completeness and reliability of the dataset, prevent biased or misleading results, handle missing values through imputation, and leverage the presence of missing values for valuable insights. Ultimately, this process safeguards the integrity and accuracy of subsequent data analysis and modeling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a function for checking null values in percentage in relation to length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "\n",
    "    \"\"\" Function for checking null values in percentage in relation to length of the dataset \"\"\"\n",
    "\n",
    "    if data.isnull().any().any() == False :\n",
    "\n",
    "        print(\"There Are No Missing Values\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        missing_values = data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "        missing_val_percent = ((data.isnull().sum()/len(data)).sort_values(ascending=False))\n",
    "\n",
    "        missing_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage %': missing_val_percent})\n",
    "\n",
    "        return missing_df[missing_df['Percentage %'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Missing Values in Book Ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There Are No Missing Values\n"
     ]
    }
   ],
   "source": [
    "missing_values(book_ratings) # checking for missing values in book ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By confirming that there are no missing values in the Book Ratings dataset, we can proceed with confidence knowing that all the required data is available for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Missing Values in the Books dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image-URL-L</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Publisher</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Book-Author</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Missing Values  Percentage %\n",
       "Image-URL-L               3      0.000011\n",
       "Publisher                 2      0.000007\n",
       "Book-Author               1      0.000004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values(books) # checking for missing values in books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function has identified three columns with missing values: Image-URL-L, Publisher, and Book-Author.\n",
    "\n",
    "- Image-URL-L: There are 3 missing values in the Image-URL-L column, which represents the URL of the large-sized book image.\n",
    "- Publisher: There are 2 missing values in the Publisher column, which represents the publisher of the book.\n",
    "- Book-Author: There is 1 missing value in the Book-Author column, which represents the author of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Missing Values in Users dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>110762</td>\n",
       "      <td>0.397199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Missing Values  Percentage %\n",
       "Age          110762      0.397199"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values(users) # checking for missing values in users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function has identified one column with missing values: Age.\n",
    "\n",
    "Age: There are 110,762 missing values in the Age column, which represents the age of the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Dropping Columns with Missing Values\n",
    "\n",
    "After dropping specified columns, this can be useful when dealing with columns that have a significant number of missing values or when those columns are not relevant for the analysis or modeling task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a function to drop columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropping_columns(data, columns):\n",
    "\n",
    "    \"\"\"A simple function to drop columns with missing values\"\"\"\n",
    "\n",
    "    drop_column = data.drop(columns=columns, inplace = True)\n",
    "    \n",
    "    return drop_column\n",
    "\n",
    "columns_to_drop = users[['Age']]\n",
    "\n",
    "dropping_columns(users, columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a function to remove the rows of columns that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(data, columns):\n",
    "    \n",
    "    \"\"\"A simple function to remove the rows of columns that have missing values \"\"\"\n",
    "    \n",
    "    new_data = data.dropna(subset=columns, inplace=True)\n",
    "    return new_data\n",
    "\n",
    "col = ['Image-URL-L', 'Publisher', 'Book-Author']\n",
    "drop_rows(books, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a function to merge the datasets based on a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>washington, dc, usa</td>\n",
       "      <td>034542252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>0425163393</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>0515087122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>0553275739</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>0553578596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>0553579606</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID                   Location        ISBN  Book-Rating\n",
       "0              2  stockton, california, usa  0195153448            0\n",
       "1              7        washington, dc, usa   034542252            0\n",
       "2              8   timmins, ontario, canada  0002005018            5\n",
       "3              8   timmins, ontario, canada  0060973129            0\n",
       "4              8   timmins, ontario, canada  0374157065            0\n",
       "...          ...                        ...         ...          ...\n",
       "1149775   278854      portland, oregon, usa  0425163393            7\n",
       "1149776   278854      portland, oregon, usa  0515087122            0\n",
       "1149777   278854      portland, oregon, usa  0553275739            6\n",
       "1149778   278854      portland, oregon, usa  0553578596            0\n",
       "1149779   278854      portland, oregon, usa  0553579606            8\n",
       "\n",
       "[1149780 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_dataframe(data_0, data_1, merge_column):\n",
    "    \"\"\"A function to merge the datasets based on a given column\"\"\"\n",
    "    new_df = data_0.merge(data_1, on=merge_column)\n",
    "    return new_df\n",
    "\n",
    "df_rating = merge_dataframe(users, book_ratings, \"User-ID\")\n",
    "df_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is called to merge the users and book_ratings datasets based on the column \"User-ID\". The resulting merged dataset is stored in the variable df_rating. This allows us to combine the information from both datasets based on the common column \"User-ID\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirming that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There Are No Missing Values\n"
     ]
    }
   ],
   "source": [
    "missing_values(df_rating) # checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirming that there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has No Duplicates\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(df_rating) # checking for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting information and stats for our 'Merged' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Merged DataFrame\n",
      "has 1149780 rows and 4 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   Location     1149780 non-null  object\n",
      " 2   ISBN         1149780 non-null  object\n",
      " 3   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 43.9+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "            User-ID   Book-Rating\n",
      "count  1.149780e+06  1.149780e+06\n",
      "mean   1.403864e+05  2.866950e+00\n",
      "std    8.056228e+04  3.854184e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n"
     ]
    }
   ],
   "source": [
    "get_info_shape_stats(df_rating, 'Merged DataFrame') # checking the dataset info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged dataset, named \"Merged DataFrame,\" contains a total of 1,149,780 rows and 4 columns. It combines the information from the \"users\" and \"book_ratings\" datasets based on the \"User-ID\" column.\n",
    "\n",
    "The dataset comprises two numerical columns, \"User-ID\" and \"Book-Rating,\" and two categorical columns, \"Location\" and \"ISBN.\" The \"User-ID\" represents the unique identifier of the user, \"Location\" denotes the location of the user, \"ISBN\" refers to the unique identifier of the book, and \"Book-Rating\" represents the rating given by the user for a particular book.\n",
    "\n",
    "The dataset does not have any missing values, as indicated by the non-null counts for all columns. The descriptive statistics reveal that the average book rating is approximately 2.87, with a standard deviation of 3.85. The ratings range from 0 to 10, with a significant portion of the ratings being 0.\n",
    "\n",
    "This merged dataset provides valuable information for further analysis and insights into the book ratings given by users and their corresponding locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging the new dataset with the book dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11400</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>41385</td>\n",
       "      <td>sudbury, ontario, canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN           Book-Title           Book-Author Year-Of-Publication  \\\n",
       "0  0195153448  Classical Mythology    Mark P. O. Morford                2002   \n",
       "1  0002005018         Clara Callan  Richard Bruce Wright                2001   \n",
       "2  0002005018         Clara Callan  Richard Bruce Wright                2001   \n",
       "3  0002005018         Clara Callan  Richard Bruce Wright                2001   \n",
       "4  0002005018         Clara Callan  Richard Bruce Wright                2001   \n",
       "\n",
       "                 Publisher                                        Image-URL-S  \\\n",
       "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                         Image-URL-L  User-ID  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...        2   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...        8   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...    11400   \n",
       "3  http://images.amazon.com/images/P/0002005018.0...    11676   \n",
       "4  http://images.amazon.com/images/P/0002005018.0...    41385   \n",
       "\n",
       "                    Location  Book-Rating  \n",
       "0  stockton, california, usa            0  \n",
       "1   timmins, ontario, canada            5  \n",
       "2    ottawa, ontario, canada            0  \n",
       "3              n/a, n/a, n/a            8  \n",
       "4   sudbury, ontario, canada            0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" merging the new dataset with the book dataset \"\"\"\n",
    "df_books = merge_dataframe(books, df_rating, 'ISBN')\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting information and stats for our 'Combined' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Combined Dataset\n",
      "has 1031129 rows and 11 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1031129 entries, 0 to 1031128\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   ISBN                 1031129 non-null  object\n",
      " 1   Book-Title           1031129 non-null  object\n",
      " 2   Book-Author          1031129 non-null  object\n",
      " 3   Year-Of-Publication  1031129 non-null  object\n",
      " 4   Publisher            1031129 non-null  object\n",
      " 5   Image-URL-S          1031129 non-null  object\n",
      " 6   Image-URL-M          1031129 non-null  object\n",
      " 7   Image-URL-L          1031129 non-null  object\n",
      " 8   User-ID              1031129 non-null  int64 \n",
      " 9   Location             1031129 non-null  object\n",
      " 10  Book-Rating          1031129 non-null  int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 94.4+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "            User-ID   Book-Rating\n",
      "count  1.031129e+06  1.031129e+06\n",
      "mean   1.405945e+05  2.839039e+00\n",
      "std    8.052485e+04  3.854152e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.041500e+04  0.000000e+00\n",
      "50%    1.412100e+05  0.000000e+00\n",
      "75%    2.114260e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n"
     ]
    }
   ],
   "source": [
    "get_info_shape_stats(df_books, \"Combined Dataset\") # check merged dataset info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined dataset, named \"Combined Dataset,\" contains a total of 1,031,129 rows and 11 columns. It merges the information from the \"books\" dataset and the previously merged \"df_rating\" dataset based on the \"User-ID\" column and the \"ISBN\" column, respectively.\n",
    "\n",
    "The dataset comprises two numerical columns, \"User-ID\" and \"Book-Rating,\" and nine categorical columns: \"ISBN,\" \"Book-Title,\" \"Book-Author,\" \"Year-Of-Publication,\" \"Publisher,\" \"Image-URL-S,\" \"Image-URL-M,\" \"Image-URL-L,\" and \"Location.\" These columns provide information about the book's ISBN, title, author, publication year, publisher, and image URLs, as well as the user's ID and location.\n",
    "\n",
    "Similar to the previous merged dataset, the combined dataset does not have any missing values, as indicated by the non-null counts for all columns. The descriptive statistics show that the average book rating is approximately 2.84, with a standard deviation of 3.85. The ratings range from 0 to 10, with a significant portion of the ratings being 0.\n",
    "\n",
    "This combined dataset provides a comprehensive collection of information about books, including their details, user ratings, and user demographics. It can be used for various analyses and recommendations in the domain of book recommendations and user behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirming that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There Are No Missing Values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_values(df_books) # check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirming that there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has No Duplicates\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(df_books) # check for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. EDA: EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1: Popularity Based Recommendation System\n",
    "\n",
    "A Popularity Based Recommendation System is a simple and straightforward approach to recommend items based on their overall popularity. It suggests popular items to all users, regardless of their individual preferences. This system relies on the assumption that popular items are more likely to be of interest to a larger audience.\n",
    "\n",
    "However, one limitation of a Popularity Based Recommendation System is that it does not consider individual user preferences or specific interests. It treats all users equally and recommends the same popular items to everyone. Therefore, it may not provide personalized recommendations that align with the unique tastes and preferences of each user.\n",
    "\n",
    "Despite its simplicity, a Popularity Based Recommendation System can be effective in situations where personalized data is limited or when the goal is to promote popular and trending items to a broad user audience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a function that calculates the popularity of values in a specific column of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wild Animus</th>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Lovely Bones: A Novel</th>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Da Vinci Code</th>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Painted House</th>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Nanny Diaries: A Novel</th>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Jones's Diary</th>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Secret Life of Bees</th>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Divine Secrets of the Ya-Ya Sisterhood: A Novel</th>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Red Tent (Bestselling Backlist)</th>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angels &amp;amp; Demons</th>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Life of Pi</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Falling on Cedars</th>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Summons</th>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Notebook</th>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Testament</th>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House of Sand and Fog</th>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where the Heart Is (Oprah's Book Club (Paperback))</th>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Pelican Brief</th>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))</th>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer Sisters</th>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Book-Title\n",
       "Wild Animus                                               2502\n",
       "The Lovely Bones: A Novel                                 1295\n",
       "The Da Vinci Code                                          898\n",
       "A Painted House                                            838\n",
       "The Nanny Diaries: A Novel                                 828\n",
       "Bridget Jones's Diary                                      815\n",
       "The Secret Life of Bees                                    774\n",
       "Divine Secrets of the Ya-Ya Sisterhood: A Novel            740\n",
       "The Red Tent (Bestselling Backlist)                        723\n",
       "Angels &amp; Demons                                        670\n",
       "Life of Pi                                                 664\n",
       "Snow Falling on Cedars                                     662\n",
       "The Summons                                                655\n",
       "The Notebook                                               650\n",
       "The Testament                                              617\n",
       "House of Sand and Fog                                      588\n",
       "Where the Heart Is (Oprah's Book Club (Paperback))         585\n",
       "The Pelican Brief                                          581\n",
       "Harry Potter and the Sorcerer's Stone (Harry Po...         575\n",
       "Summer Sisters                                             573"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_popularity(df, column_name):\n",
    "\n",
    "    \"\"\"Calculates the popularity of values in a specific column of a dataframe\"\"\"\n",
    "\n",
    "    popularity_df = pd.DataFrame(df[column_name].value_counts())\n",
    "    return popularity_df\n",
    "\n",
    "popularity_df = calculate_popularity(df_books, 'Book-Title')\n",
    "popularity_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe, popularity_df, displays the top 20 book titles and their corresponding popularity counts. The popularity is based on the frequency of each book title occurrence in the dataset. This information can be valuable for building recommendation systems or understanding the distribution of popularity among different items.\n",
    "\n",
    "From the list of top books, it can be observed that certain titles have significantly higher occurrence counts compared to others. These highly popular books, such as \"Wild Animus,\" \"The Lovely Bones: A Novel,\" and \"The Da Vinci Code,\" have likely gained widespread recognition and reader interest. This observation suggests that these books have resonated with a large audience and have potentially garnered positive reviews or word-of-mouth recommendations. These popular books can serve as a starting point for further analysis and recommendation strategies in the context of a book recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a function that filters a dataframe to include only users who have actively rated more than a specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>85526</td>\n",
       "      <td>victoria, british columbia, canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>177458</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>110912</td>\n",
       "      <td>milpitas, california, usa</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>197659</td>\n",
       "      <td>indiana, pennsylvania, usa</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title  \\\n",
       "3   0002005018                                       Clara Callan   \n",
       "6   0002005018                                       Clara Callan   \n",
       "10  0002005018                                       Clara Callan   \n",
       "21  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "26  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "\n",
       "             Book-Author Year-Of-Publication              Publisher  \\\n",
       "3   Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "6   Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "10  Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "21      Gina Bari Kolata                1999   Farrar Straus Giroux   \n",
       "26      Gina Bari Kolata                1999   Farrar Straus Giroux   \n",
       "\n",
       "                                          Image-URL-S  \\\n",
       "3   http://images.amazon.com/images/P/0002005018.0...   \n",
       "6   http://images.amazon.com/images/P/0002005018.0...   \n",
       "10  http://images.amazon.com/images/P/0002005018.0...   \n",
       "21  http://images.amazon.com/images/P/0374157065.0...   \n",
       "26  http://images.amazon.com/images/P/0374157065.0...   \n",
       "\n",
       "                                          Image-URL-M  \\\n",
       "3   http://images.amazon.com/images/P/0002005018.0...   \n",
       "6   http://images.amazon.com/images/P/0002005018.0...   \n",
       "10  http://images.amazon.com/images/P/0002005018.0...   \n",
       "21  http://images.amazon.com/images/P/0374157065.0...   \n",
       "26  http://images.amazon.com/images/P/0374157065.0...   \n",
       "\n",
       "                                          Image-URL-L  User-ID  \\\n",
       "3   http://images.amazon.com/images/P/0002005018.0...    11676   \n",
       "6   http://images.amazon.com/images/P/0002005018.0...    85526   \n",
       "10  http://images.amazon.com/images/P/0002005018.0...   177458   \n",
       "21  http://images.amazon.com/images/P/0374157065.0...   110912   \n",
       "26  http://images.amazon.com/images/P/0374157065.0...   197659   \n",
       "\n",
       "                              Location  Book-Rating  \n",
       "3                        n/a, n/a, n/a            8  \n",
       "6   victoria, british columbia, canada            0  \n",
       "10             ottawa, ontario, canada            0  \n",
       "21           milpitas, california, usa           10  \n",
       "26          indiana, pennsylvania, usa            9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_active_users(dataframe, threshold):\n",
    "\n",
    "    \"\"\"Filter the dataframe to include only users who have actively rated more than the threshold\"\"\"\n",
    "    \n",
    "    # Filter the DataFrame based on the count of each unique User-ID\n",
    "    user_counts = dataframe['User-ID'].value_counts()\n",
    "    filter = user_counts > threshold\n",
    "\n",
    "    # Get the index values of the filtered rows\n",
    "    filtered_index = filter[filter].index\n",
    "\n",
    "    # Create a new DataFrame by selecting only the rows where User-ID is in the filtered index\n",
    "    filtered_df = dataframe[dataframe['User-ID'].isin(filtered_index)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "df_filtered = filter_active_users(df_books, 300)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset df_filtered is a subset of the original dataframe df_books, filtered to include only active users who have rated more than 300 times. This filtering process helps focus the analysis or recommendation strategies on users who have actively engaged with the dataset, providing a more targeted dataset for further exploration. The filtered dataset can now be used to gain insights into the preferences and behaviors of highly active users or to develop personalized recommendation systems based on their extensive ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function that calculates the number of times each book has been rated in a given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>85526</td>\n",
       "      <td>victoria, british columbia, canada</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>177458</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>110912</td>\n",
       "      <td>milpitas, california, usa</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>197659</td>\n",
       "      <td>indiana, pennsylvania, usa</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0002005018                                       Clara Callan   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0002005018                                       Clara Callan   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "\n",
       "            Book-Author Year-Of-Publication              Publisher  \\\n",
       "0  Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "1  Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "2  Richard Bruce Wright                2001  HarperFlamingo Canada   \n",
       "3      Gina Bari Kolata                1999   Farrar Straus Giroux   \n",
       "4      Gina Bari Kolata                1999   Farrar Straus Giroux   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0374157065.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0374157065.0...   \n",
       "\n",
       "                                         Image-URL-L  User-ID  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...    11676   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...    85526   \n",
       "2  http://images.amazon.com/images/P/0002005018.0...   177458   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   110912   \n",
       "4  http://images.amazon.com/images/P/0374157065.0...   197659   \n",
       "\n",
       "                             Location  Book-Rating  rating_count  \n",
       "0                       n/a, n/a, n/a            8             3  \n",
       "1  victoria, british columbia, canada            0             3  \n",
       "2             ottawa, ontario, canada            0             3  \n",
       "3           milpitas, california, usa           10             2  \n",
       "4          indiana, pennsylvania, usa            9             2  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_rating_count(dataframe):\n",
    "\n",
    "    \"\"\"A Simple Function to Calculate the Number of Times each book has been rated\"\"\"\n",
    "\n",
    "    # Group the dataframe by 'Book-Title' and count the occurrences of 'Book-Rating' for each title\n",
    "    rating_count = dataframe.groupby('Book-Title')['Book-Rating'].count().reset_index()\n",
    "\n",
    "    # Rename the 'Book-Rating' column to 'rating_count'\n",
    "    rating_count.rename(columns={'Book-Rating': 'rating_count'}, inplace=True)\n",
    "\n",
    "    # Merge the original dataframe with the 'rating_count' dataframe based on 'Book-Title'\n",
    "    new_df = dataframe.merge(rating_count, on='Book-Title')\n",
    "\n",
    "    # Display the first few rows of the merged dataframe\n",
    "    return new_df\n",
    "\n",
    "new_book_df = calculate_rating_count(df_filtered)\n",
    "new_book_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the number of times each book in the dataframe has been rated and adds a new column 'rating_count' to the dataframe. The merged dataframe can be used to analyze the popularity or rating frequency of books, which can be valuable for building recommendation systems or understanding user preferences.\n",
    "\n",
    "The merged dataframe, new_book_df, can be utilized to analyze the popularity or rating frequency of books. This information can be valuable for various purposes, such as building recommendation systems or understanding user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function to filter a dataframe based on a minimum rating count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>36836</td>\n",
       "      <td>raleigh, north carolina, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>46398</td>\n",
       "      <td>san antonio, texas, usa</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>113270</td>\n",
       "      <td>evanston, illinois, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>113519</td>\n",
       "      <td>pleasanton, california, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN              Book-Title Book-Author Year-Of-Publication  \\\n",
       "5  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "6  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "7  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "8  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "9  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "\n",
       "          Publisher                                        Image-URL-S  \\\n",
       "5  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "7  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "8  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "9  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0399135782.0...   \n",
       "7  http://images.amazon.com/images/P/0399135782.0...   \n",
       "8  http://images.amazon.com/images/P/0399135782.0...   \n",
       "9  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         Image-URL-L  User-ID  \\\n",
       "5  http://images.amazon.com/images/P/0399135782.0...    11676   \n",
       "6  http://images.amazon.com/images/P/0399135782.0...    36836   \n",
       "7  http://images.amazon.com/images/P/0399135782.0...    46398   \n",
       "8  http://images.amazon.com/images/P/0399135782.0...   113270   \n",
       "9  http://images.amazon.com/images/P/0399135782.0...   113519   \n",
       "\n",
       "                       Location  Book-Rating  rating_count  \n",
       "5                 n/a, n/a, n/a            9            88  \n",
       "6  raleigh, north carolina, usa            0            88  \n",
       "7       san antonio, texas, usa            9            88  \n",
       "8       evanston, illinois, usa            0            88  \n",
       "9   pleasanton, california, usa            0            88  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_rating_count(dataframe, threshold):\n",
    "    \n",
    "    \"\"\"A Simple Funtion to Filter the dataframe based on a minimum rating count\"\"\"\n",
    "\n",
    "    # Apply the filter to the 'dataframe' using the 'loc' function\n",
    "    filtered_df = dataframe.loc[dataframe['rating_count'] >= threshold, :]\n",
    "\n",
    "    # Display the first few rows of the filtered dataframe\n",
    "    return filtered_df\n",
    "\n",
    "rating_more_50 = filter_rating_count(new_book_df, 50)\n",
    "rating_more_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting rating_more_50 dataframe contains the filtered rows that have a rating count of 50 or more. It retains the same columns as the original dataframe, including 'ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'User-ID', 'Location', 'Book-Rating', and 'rating_count'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing the dataset containing User-ID and Book-Title for books with multiple ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book_user_id_df dataframe is created by selecting the 'User-ID' and 'Book-Title' columns from the rating_more_50 dataframe. This subset of data allows us to examine instances where a user has rated a book more than once.\n",
    "\n",
    "The dataframe displays the User-ID and corresponding Book-Title for each entry. Each row represents a user's rating for a particular book. By examining this dataframe, we can observe multiple ratings for the same book by different users, indicating varying opinions or multiple readings of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11676</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36836</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46398</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113270</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>113519</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171955</th>\n",
       "      <td>235105</td>\n",
       "      <td>M Is for Malice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171956</th>\n",
       "      <td>242824</td>\n",
       "      <td>M Is for Malice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171957</th>\n",
       "      <td>254899</td>\n",
       "      <td>M Is for Malice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171958</th>\n",
       "      <td>258534</td>\n",
       "      <td>M Is for Malice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171959</th>\n",
       "      <td>269566</td>\n",
       "      <td>M Is for Malice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35871 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID              Book-Title\n",
       "5         11676  The Kitchen God's Wife\n",
       "6         36836  The Kitchen God's Wife\n",
       "7         46398  The Kitchen God's Wife\n",
       "8        113270  The Kitchen God's Wife\n",
       "9        113519  The Kitchen God's Wife\n",
       "...         ...                     ...\n",
       "171955   235105         M Is for Malice\n",
       "171956   242824         M Is for Malice\n",
       "171957   254899         M Is for Malice\n",
       "171958   258534         M Is for Malice\n",
       "171959   269566         M Is for Malice\n",
       "\n",
       "[35871 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_user_id_df = rating_more_50[['User-ID', 'Book-Title']]\n",
    "book_user_id_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information provides insights into cases where users have rated the same book multiple times, possibly due to multiple readings or diverse opinions. Analyzing this dataset can help understand user preferences and the range of ratings for popular books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Duplicate Rows in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows constitute of 4.2 % of our dataset\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(book_user_id_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis reveals that duplicated rows make up approximately 4.2% of the dataset. Duplicate rows can occur when a user has rated the same book multiple times or due to data entry errors. Identifying and handling duplicate rows is important to ensure data integrity and avoid biased analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the final dataframe and removing the duplicates in the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>36836</td>\n",
       "      <td>raleigh, north carolina, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>46398</td>\n",
       "      <td>san antonio, texas, usa</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>113270</td>\n",
       "      <td>evanston, illinois, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>113519</td>\n",
       "      <td>pleasanton, california, usa</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN              Book-Title Book-Author Year-Of-Publication  \\\n",
       "5  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "6  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "7  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "8  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "9  0399135782  The Kitchen God's Wife     Amy Tan                1991   \n",
       "\n",
       "          Publisher                                        Image-URL-S  \\\n",
       "5  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "7  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "8  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "9  Putnam Pub Group  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0399135782.0...   \n",
       "7  http://images.amazon.com/images/P/0399135782.0...   \n",
       "8  http://images.amazon.com/images/P/0399135782.0...   \n",
       "9  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         Image-URL-L  User-ID  \\\n",
       "5  http://images.amazon.com/images/P/0399135782.0...    11676   \n",
       "6  http://images.amazon.com/images/P/0399135782.0...    36836   \n",
       "7  http://images.amazon.com/images/P/0399135782.0...    46398   \n",
       "8  http://images.amazon.com/images/P/0399135782.0...   113270   \n",
       "9  http://images.amazon.com/images/P/0399135782.0...   113519   \n",
       "\n",
       "                       Location  Book-Rating  rating_count  \n",
       "5                 n/a, n/a, n/a            9            88  \n",
       "6  raleigh, north carolina, usa            0            88  \n",
       "7       san antonio, texas, usa            9            88  \n",
       "8       evanston, illinois, usa            0            88  \n",
       "9   pleasanton, california, usa            0            88  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = rating_more_50.drop_duplicates(subset=['User-ID', 'Book-Title'])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting information and stats for our 'Final DataFrame' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset: Final DataFrame\n",
      "has 34365 rows and 12 columns\n",
      "---------------------------\n",
      "---------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34365 entries, 5 to 171959\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ISBN                 34365 non-null  object\n",
      " 1   Book-Title           34365 non-null  object\n",
      " 2   Book-Author          34365 non-null  object\n",
      " 3   Year-Of-Publication  34365 non-null  object\n",
      " 4   Publisher            34365 non-null  object\n",
      " 5   Image-URL-S          34365 non-null  object\n",
      " 6   Image-URL-M          34365 non-null  object\n",
      " 7   Image-URL-L          34365 non-null  object\n",
      " 8   User-ID              34365 non-null  int64 \n",
      " 9   Location             34365 non-null  object\n",
      " 10  Book-Rating          34365 non-null  int64 \n",
      " 11  rating_count         34365 non-null  int64 \n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "---------------------------\n",
      "----------------------------\n",
      "             User-ID   Book-Rating  rating_count\n",
      "count   34365.000000  34365.000000  34365.000000\n",
      "mean   139954.101528      1.824182     84.931209\n",
      "std     80809.661076      3.441116     33.873243\n",
      "min      2276.000000      0.000000     50.000000\n",
      "25%     69355.000000      0.000000     60.000000\n",
      "50%    138844.000000      0.000000     73.000000\n",
      "75%    212645.000000      0.000000     99.000000\n",
      "max    278418.000000     10.000000    223.000000\n"
     ]
    }
   ],
   "source": [
    "get_info_shape_stats(final_df, 'Final DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final DataFrame consists of 34,365 rows and 12 columns. Here is a summary of the dataset:\n",
    "\n",
    "The DataFrame contains both numerical and categorical columns.\n",
    "The columns include 'ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'User-ID', 'Location', 'Book-Rating', and 'rating_count'.\n",
    "The 'User-ID' column represents the ID of the user who rated the book.\n",
    "The 'Book-Rating' column contains the ratings given by users for the books.\n",
    "The 'rating_count' column indicates the number of times each book has been rated.\n",
    "Here are some statistical insights about the dataset:\n",
    "\n",
    "The average book rating is approximately 1.82.\n",
    "The average rating count for books is around 84.93.\n",
    "The minimum rating count is 50, indicating that only books with at least 50 ratings are included in the dataset.\n",
    "The maximum rating count is 223, suggesting that some books have received a high number of ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2: Collaborative Filtering Recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is a method of making automatic predictions(i.e filtering) about the interests of a user by collecting preferences or taste information from many users on the aggregate(i.e collaborating). There are two main apporoaches to collaborative filtering :\n",
    "\n",
    "- Item - Item CF : \"Users who like this item also liked...\"\n",
    "- User - Item CF : \"Users who are similar to you also liked\"\n",
    "\n",
    "Model based collaborative filtering approach involves building machine learning algorithms to predict user's ratings. They involve dimensionality reduction methods that reduce high dimensional matrix containing abundant number of missing values with a much smaller matrix in a lower-dimensional space. The goal of this section is to compare SVD and SVDpp algorithms, try optimizing parameters and explore obtained results.Let's start by preparing our dataset for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a new dataframe that contains only the relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe that contains only the relevant columns \n",
    "\n",
    "final_df.rename(columns = {'User-ID':'user_id' ,'ISBN':'isbn' ,'Book-Rating':'book_rating'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out least active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: users with at least 3 ratings\n",
      "Number of records: 34361\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Filtering out least active users \"\"\"\n",
    "\n",
    "user_ratings_threshold = 3\n",
    "\n",
    "filter_users = final_df['user_id'].value_counts()\n",
    "filter_users_list = filter_users[filter_users >= user_ratings_threshold].index.to_list()\n",
    "\n",
    "df_ratings_top = final_df[final_df['user_id'].isin(filter_users_list)]\n",
    "\n",
    "print('Filter: users with at least %d ratings\\nNumber of records: %d' % (user_ratings_threshold, len(df_ratings_top))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the Top 10% Most Frequently Rated Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: Top 10% Most Frequently Rated Books\n",
      "Number of records: 12626\n"
     ]
    }
   ],
   "source": [
    "book_ratings_threshold_perc = 0.1\n",
    "book_ratings_threshold = len(df_ratings_top['isbn'].unique()) * book_ratings_threshold_perc\n",
    "\n",
    "filter_books_list = df_ratings_top['isbn'].value_counts().head(int(book_ratings_threshold)).index.to_list()\n",
    "df_ratings_top = df_ratings_top[df_ratings_top['isbn'].isin(filter_books_list)]\n",
    "\n",
    "print('Filter: Top %d%% Most Frequently Rated Books\\nNumber of records: %d' % (book_ratings_threshold_perc*100, len(df_ratings_top)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3: SVD (Singular Value Decomposition) recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD (Singular Value Decomposition) is a popular recommendation system technique used to provide personalized recommendations to users. It is based on the mathematical concept of matrix factorization.\n",
    "\n",
    "In SVD, the user-item interaction matrix is decomposed into three separate matrices: a user matrix, an item matrix, and a diagonal matrix. This decomposition allows us to represent users and items in a lower-dimensional space, capturing the underlying relationships and patterns in the data.\n",
    "\n",
    "By reducing the dimensionality of the user-item matrix, SVD can effectively identify latent factors that contribute to user preferences and item characteristics. These latent factors can be used to generate recommendations by predicting missing ratings or estimating the likelihood of a user's preference for a particular item. SVD-based recommendation systems have been successful in various domains, including e-commerce, movie recommendations, and content streaming platforms.\n",
    "\n",
    "SVD recommendation systems offer several advantages. They can handle sparse data efficiently, making them suitable for large-scale datasets. They also provide interpretable factors that can be used to understand the reasons behind recommendations. However, SVD-based systems may face challenges when dealing with new or cold-start users or items, as the model requires sufficient historical data for accurate predictions. Overall, SVD is a powerful technique for building personalized recommendation systems that can enhance user experiences and drive engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function to read our data into a Suprise Dataset format, instatiate model and perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(df, model_class, rating_scale=(1, 10), cv=3):\n",
    "\n",
    "    \"\"\" A function to read our data into a Suprise Dataset format, instatiate model and perform cross validation\"\"\"\n",
    "\n",
    "    reader = Reader(rating_scale=rating_scale)\n",
    "    data = Dataset.load_from_df(df[['user_id', 'isbn', 'book_rating']], reader)\n",
    "    \n",
    "    model = model_class()\n",
    "    cv_results = cross_validate(model, data, cv=cv)\n",
    "    cv_results_df = pd.DataFrame(cv_results).mean()\n",
    "    \n",
    "    return cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Results:\n",
      "test_rmse    3.403562\n",
      "test_mae     2.717575\n",
      "fit_time     1.300712\n",
      "test_time    0.133902\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = df_ratings_top.copy()\n",
    "svd_results = evaluate_model(df, SVD)\n",
    "print(\"SVD Results:\")\n",
    "print(svd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD (Singular Value Decomposition) recommendation system model was evaluated using cross-validation. The results indicate the following average metrics across the cross-validation folds:\n",
    "\n",
    "- The average Root Mean Squared Error (RMSE) is 3.403562. RMSE measures the difference between the predicted ratings and the actual ratings. Lower RMSE values indicate better accuracy of the model in predicting ratings.\n",
    "\n",
    "- The average Mean Absolute Error (MAE) is 2.717575. MAE represents the absolute difference between the predicted and actual ratings. Lower MAE values indicate better accuracy in predicting ratings.\n",
    "\n",
    "- The average fit time is 1.300712 seconds. Fit time refers to the time taken to train the model on the dataset.\n",
    "\n",
    "- The average test time is 0.133902 seconds. Test time represents the time taken to predict ratings for the test data.\n",
    "\n",
    "These metrics provide insights into the performance and efficiency of the SVD recommendation system model. Lower RMSE and MAE values suggest that the model performs well in predicting ratings, while shorter fit and test times indicate faster model training and prediction processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incorporating SVDpp(Singular Value Decomposition with Implicit Feedback) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD++ (Singular Value Decomposition with Implicit Feedback) is an advanced algorithm used in collaborative filtering-based recommendation systems. Collaborative filtering is a popular approach to recommend items to users based on their similarity to other users or items. SVD++ takes this approach further by incorporating both explicit and implicit feedback from users.\n",
    "\n",
    "Explicit feedback refers to the direct ratings or reviews given by users for items, indicating their preferences. Implicit feedback, on the other hand, includes indirect indicators of user preferences, such as purchase history, browsing behavior, or click-through rates. By considering implicit feedback, SVD++ can capture additional information about user preferences that might not be explicitly stated.\n",
    "\n",
    "The algorithm utilizes the concept of singular value decomposition, which breaks down the user-item rating matrix into lower-dimensional representations. SVD++ extends this decomposition by incorporating a model that captures the influence of implicit feedback. It takes into account factors such as the observed ratings, user biases, and item biases to improve the accuracy of recommendations.\n",
    "\n",
    "By combining both explicit and implicit feedback, SVD++ addresses the limitations of traditional collaborative filtering methods that solely rely on explicit ratings. It can provide more personalized and accurate recommendations by considering the underlying patterns and interactions between users and items. SVD++ has demonstrated its effectiveness in various recommendation scenarios and has become a popular choice for building recommendation systems in both research and industry domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDpp Results:\n",
      "test_rmse     3.615515\n",
      "test_mae      2.842385\n",
      "fit_time     10.743599\n",
      "test_time     0.467458\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "svdpp_results = evaluate_model(df, SVDpp)\n",
    "print(\"SVDpp Results:\")\n",
    "print(svdpp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained from SVD++ show a slightly higher level of prediction errors compared to the previous SVD model. The test_rmse value of 3.615515 indicates that SVD++ has slightly larger deviations from the actual ratings. Similarly, the test_mae value of 2.842385 suggests that the average prediction errors of SVD++ are slightly higher than those of SVD. These findings imply that SVD++ may not perform as well in accurately predicting user ratings compared to SVD.\n",
    "\n",
    "In terms of computational performance, SVD++ exhibits a significantly higher fit_time of 10.743599 seconds. This indicates that the training process for SVD++ takes longer than that of SVD, which had a fit_time of 1.300712 seconds. However, the test_time for SVD++ is only slightly higher at 0.467458 seconds compared to SVD's test_time of 0.133902 seconds. Despite the longer training time, the prediction time of SVD++ remains relatively efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing SVD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter  tuning the SVD model minimising the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVD Model RMSE 3.301179728274886\n",
      "Best Paramers {'n_factors': 10, 'n_epochs': 50, 'lr_all': 0.001, 'reg_all': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 11.9min finished\n"
     ]
    }
   ],
   "source": [
    "df = df_ratings_top.copy()\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(df[['user_id', 'isbn', 'book_rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': [10, 100, 500],\n",
    "    'n_epochs': [5, 20, 50], \n",
    "    'lr_all': [0.001, 0.005, 0.02],\n",
    "    'reg_all': [0.005, 0.02, 0.1]}\n",
    "\n",
    "gs_model = GridSearchCV(\n",
    "    algo_class = SVD,\n",
    "    param_grid = param_grid,\n",
    "    n_jobs = -1,\n",
    "    joblib_verbose = 5)\n",
    "\n",
    "gs_model.fit(data)\n",
    "\n",
    " #Train the SVD model with the parameters that minimise the root mean squared error\n",
    " \n",
    "best_SVD = gs_model.best_estimator['rmse']\n",
    "print(\"Tuned SVD Model RMSE\", gs_model.best_score['rmse'])\n",
    "print(\"Best Paramers\", gs_model.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the grid search, the best SVD model was obtained with the following parameters: n_factors = 10, n_epochs = 50, lr_all = 0.001, and reg_all = 0.1. The tuned SVD model achieved an RMSE of 3.301179728274886, which is slightly lower than the previous results obtained from the default SVD and SVD++ models. This indicates that the tuned SVD model provides improved accuracy in predicting user ratings.\n",
    "\n",
    "The comparison of results suggests that the hyperparameter tuning process was successful in finding a set of parameters that minimize the RMSE. By fine-tuning the SVD model, we were able to improve the prediction performance and reduce the error in rating predictions. Therefore, the tuned SVD model with the optimized parameters can be considered as a better choice for the recommendation system compared to the default SVD and SVD++ models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. MODEL DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
